{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os    \n",
    "os.environ['THEANO_FLAGS'] = \"device=gpu1\"    \n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class History(keras.callbacks.Callback):\n",
    "    def __init__(self,):\n",
    "        self.history = {'loss':[], 'val_loss':[], 'fbeta_score':[], 'val_fbeta_score':[], 'acc':[], 'val_acc':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_index = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ResNet50(include_top=False, weights='imagenet', input_shape=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.layers[-1].outbound_nodes = []\n",
    "model.outputs = [model.layers[-1].output]\n",
    "output = model.get_layer('avg_pool').output\n",
    "output = Flatten()(output)\n",
    "output = Dense(output_dim=128, activation='relu')(output) # your newlayer Dense(...)\n",
    "output = Dropout(0.5)(output)\n",
    "output = Dense(output_dim=1,   activation='sigmoid')(output)\n",
    "new_model = Model(model.input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in new_model.layers[:-4]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-3, momentum=0.9),\n",
    "              metrics=['fbeta_score', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_classes = 2\n",
    "nb_epoch = 50#change to 50 afterwards\n",
    "nb_eval = 4#change to 4 afterwards\n",
    "data_augmentation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 224, 224\n",
    "# The CIFAR10 images are RGB.\n",
    "img_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import retina_dataset\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(X_train, Y_train), (X_test, Y_test) = retina_dataset.load_data(dataset_index, 224)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              validation_data=(X_test, Y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=25,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.3,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.3,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = History() \n",
    "for _ in range(nb_eval):\n",
    "    print('Eval: '+str(_))\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    new_hist = model.fit_generator(datagen.flow(X_train, Y_train ,\n",
    "                        batch_size=batch_size),\n",
    "                        samples_per_epoch=X_train.shape[0],\n",
    "                        nb_epoch=nb_epoch,\n",
    "                        validation_data=(X_test, Y_test))\n",
    "    hist.history['loss'] += new_hist.history['loss']\n",
    "    hist.history['val_loss'] += new_hist.history['val_loss']\n",
    "    hist.history['fbeta_score'] += new_hist.history['fbeta_score']\n",
    "    hist.history['val_fbeta_score'] += new_hist.history['val_fbeta_score']\n",
    "    hist.history['acc'] += new_hist.history['acc']\n",
    "    hist.history['val_acc'] += new_hist.history['val_acc']\n",
    "\n",
    "    model.save('models/resnet_pretrained_for_dataset'+str(dataset_index)+'_lr=-3_dense=128.h5')\n",
    "    model.save_weights('models/resnet_pretrained_weights_for_dataset'+str(dataset_index)+'_lr=-3_dense=128.h5')\n",
    "    plt.plot(hist.history['fbeta_score'])\n",
    "    plt.plot(hist.history['val_fbeta_score'])\n",
    "    plt.title('model f1 score')\n",
    "    plt.ylabel('f1')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.plot(hist.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.plot(hist.history['acc'])\n",
    "    plt.plot(hist.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    with open('models/resnet_pretrained_for_dataset'+str(dataset_index)+'_lr=-3_dense=128_trainning_history', 'w') as f:  # Python 3: open(..., 'wb')\n",
    "        pickle.dump(hist, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('models/resnet_pretrained_for_dataset'+str(dataset_index)+'_lr=-3_dense=128_trainning_history', 'w') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump(hist, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
